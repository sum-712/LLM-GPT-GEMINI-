# LLM-GPT-GEMINI-
2026학년도 수능 국어 문항을 기반으로 GPT와 Gemini의 문제 해결 성능을 체계적으로 비교·분석하는 프로젝트

# LLM-GPT-GEMINI: 2026학년도 수능 국어 기반 LLM 성능 비교 연구

본 프로젝트는 AI 활용 확대에 따라 대표적인 거대 언어 모델(LLM)인 GPT(OpenAI) 와  Gemini(Google) 의 2026학년도 대학수학능력시험 국어 영역 문제 해결 능력을  
정량적·정성적으로 비교·분석하기 위해 수행되었다.

단순 정답률 비교를 넘어서, 세 가지 프롬프트 엔지니어링 전략(A, B, C) 이 모델의 추론 방식, 정답률, 오류 양상에 어떤 영향을 주는지 체계적으로 검증하였다.

---

## 1. 프로젝트 개요 및 방법론

### 1.1 목적
- GPT와 Gemini의 문제 해결 능력을 동일한 조건에서 비교한다.
- 프롬프트 설계 방식(A/B/C)에 따라 LLM이 보이는 성능 변동,  
  즉 프롬프트 민감도(prompt sensitivity)를 정량적으로 측정한다.
- LLM 기반 학습·교육 프로그램 설계를 위한 최적 프롬프트 전략을 탐색한다.

### 1.2 테스트 데이터
- 2026학년도 대학수학능력시험 국어 영역
- 독서/문학 혼합형 34문항(공통 문항)

### 1.3 프롬프트 전략(핵심)
| 전략 | 명칭 | 핵심 지시 | 특징 |
|------|--------|-----------------------------|----------------|
| A | 단순 지시 | “웹 검색 없이 정답만 나열하라.” | CoT 금지, 최소 정보 제공 |
| B | 역할 부여 | “1등급 목표 고3 수험생 페르소나” + 정답만 요구 | RLHF 최적 모드 유도 |
| C | CoT 유도 | 출제 의도 → 근거 확인 → 지문 분석 → 정답 도출 (4단계 CoT) | 구조화된 사고 과정 강제 |

---

## 2. 실험 결과 및 정량 분석

### 2.1 모델별 정답 수 및 정답률  
총 34문항 기준:

| 모델 | A(단순 지시) | B(역할 부여) | C(CoT 유도) |
|------|---------------|---------------|--------------|
| Gemini Pro | 18개 (52.9%) | **28개 (82.4%)** | 26개 (76.5%) |
| GPT Pro | 5개 (14.7%) | **24개 (70.6%)** | 14개 (41.2%) |

### 2.2 결과 요약 및 주요 해석
- 가장 높은 성능을 낸 전략은 두 모델 모두 B(역할 부여) 였다.
- Gemini Pro
  - A → B 전환 시 약 **29.5%p 상승**
  - 프롬프트 형식 변화에 대한 **변동 폭이 적고 안정적**
- GPT Pro
  - A → B 전환 시 55.9%p 폭등, 프롬프트 민감도가 매우 큼
  - C(CoT 강제)에서 성능이 오히려 하락  
    → 구조화된 사고 지시가 모델 내부 최적 추론 경로와 충돌했을 가능성

---

## 3. 기술적 해석: 프롬프트 반응의 기술적 배경

### 3.1 B 방식(역할 부여)의 효과
- RLHF(인간 피드백 기반 강화 학습) 구조상  
  모델은 "1등급 목표 수험생"과 같은 역할 지시를  
  “정확도·논리성·집중도를 최대로 하는 모드”로 해석한다.
- 내부 어텐션 가중치가 강화되어  
  지문 핵심 정보 집약, 오류 감소, 논리 전개 일관성 증가.

### 3.2 C 방식(CoT 유도)의 상이한 결과
- GPT Pro
  - 4단계 분석 강제가 오히려 정답률을 낮춤
  - 내부 최적 추론 알고리즘과 강제 CoT 구조가 충돌했거나,  
    과도한 제약으로 인한 정보 손실·잡음 발생 가능성
- Gemini Pro
  - 구조화된 분석을 유연하게 내부 CoT로 변환
  - 비교적 고성능 유지

### 3.3 GPT Pro의 A(단순 지시) 극단적 취약성
- GPT Pro 정답률: 5개(14.7%)
- 단순 지시가 모델에게 문제 해결 태스크가 아닌 단순 출력 작업으로 인식되었을 가능성
- 즉, 추론 과정 생략 → 정답률 급락  
- “프롬프트 형식 하나”가 추론 경로 전체를 바꿔버리는  
  프롬프트 민감도 매우 높은 모델임을 확인

---

## 4. 결론 및 시사점

본 연구는 프롬프트 엔지니어링이 LLM 성능의 핵심 변수임을 명확하게 보여준다.

- Gemini Pro: 다양한 프롬프트에도 비교적 안정적  
- GPT Pro: 프롬프트 구성에 극도로 민감, 최적 형식(B 방식)에서만 고성능

### 교육·학습 프로그램 활용 시 시사점
1. LLM 기반 학습 도구의 성능은 프롬프트 구조에 따라 극적으로 달라질 수 있다.
2. 모델별 프롬프트 민감도가 상이하므로  
   동일한 프롬프트 전략을 모든 LLM에 공통 적용하는 것은 비효율적이다.
3. 역할 부여 기반 전략(B)은 두 모델에서 가장 안정적이며  
   학습 서비스 설계 시 기본 프롬프트로 고려할 가치가 있다.
4. CoT 전략은 모델에 따라 성능이 저하될 수 있어  
   추론 강제 지시가 항상 좋은 것은 아니다.

---

## ⭐ Support
If this project was useful to you, a Star(★) would be greatly appreciated.
프로젝트가 도움이 되었다면 Star(★)로 응원해주세요.
